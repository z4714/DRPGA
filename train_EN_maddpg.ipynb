{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import re\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "from datasets import Features, Value\n",
    "from datasets import  load_dataset, DownloadConfig\n",
    "from collections import deque,defaultdict\n",
    "import pickle\n",
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from src.utils.data_utils import format_data_sfsa\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pettingzoo.mpe import simple_adversary_v3\n",
    "from src.utils import rl_tools\n",
    "from models.maddpg.e2t_maddpg import ENMADDPG\n",
    "from models.utils import persistence\n",
    "from src.utils.data_utils import find_latest_file\n",
    "from src.utils.model_utils import pad_to_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "max_cycles = 200\n",
    "seed = 42\n",
    "\n",
    "num_episodes = 100\n",
    "episode_length = 64 \n",
    "buffer_size = 100000\n",
    "hidden_dim = 64\n",
    "actor_lr = 1e-2\n",
    "critic_lr = 1e-2\n",
    "gamma = 0.95\n",
    "tau = 1e-2\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "update_interval = 32\n",
    "minimal_size = 15\n",
    "replay_buffer = rl_tools.ReplayBuffer(buffer_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building EN_maddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_out_dim = 768\n",
    "redu_dim = 16\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_agents = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_en_dim(state_dim, redu_dim):\n",
    "\n",
    "    en_state_dims = []\n",
    "    for x in state_dim:\n",
    "        en_state_dims.append(x + redu_dim)\n",
    "    return en_state_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "state_dims=[34, 34, 34, 34, 34, 34] \n",
    "action_dims=[50, 50, 50, 50, 50, 50] \n",
    "\n",
    "en_state_dims = add_en_dim(state_dims, redu_dim)\n",
    "\n",
    "\n",
    "print(en_state_dims)\n",
    "print(action_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_input_dim = sum(state_dims) +sum(action_dims) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "print(critic_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_dir = './parameters/weights/encoders/bert_EN'\n",
    "spec_en = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.load(spec_en) if spec_en else torch.load(find_latest_file(encoders_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = \"bert-base-uncased\"\n",
    "tokenizer_fn = \"tokenizer_fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n"
     ]
    }
   ],
   "source": [
    "en_maddpg = ENMADDPG(\n",
    "    tokenizer, \n",
    "    tokenizer_fn,\n",
    "    max_length,\n",
    "    encoder, \n",
    "    en_out_dim, \n",
    "    redu_dim, \n",
    "    max_agents, \n",
    "    device, \n",
    "    actor_lr, \n",
    "    critic_lr, \n",
    "    hidden_dim, \n",
    "    state_dims, \n",
    "    action_dims, \n",
    "    critic_input_dim, \n",
    "    gamma, \n",
    "    tau\n",
    "    )\n",
    "en_maddpg = en_maddpg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660155844 B parameters in en_maddpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sum(p.numel() for p in en_maddpg.parameters())/1e9,'B parameters in en_maddpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training EN_MADDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_mpe_env_raw = load_dataset(\"graycatHCO3/RL_MPE_env_raw\")\n",
    "rl_mpe_env_raw = load_from_disk('./data/HuggingFace/RL_MPE_env_raw');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_mpe_env_raw.save_to_disk('./data/HuggingFace/RL_MPE_env_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple.txt',\n",
       " 'simple_adversary.txt',\n",
       " 'simple_crypto.txt',\n",
       " 'simple_push.txt',\n",
       " 'simple_reference.txt',\n",
       " 'simple_speaker_listener.txt',\n",
       " 'simple_spread.txt',\n",
       " 'simple_tag.txt',\n",
       " 'simple_world_comm.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_mpe_env_raw['RL_MPE_raw']['Env_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = rl_mpe_env_raw['RL_MPE_raw']['content'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_maddpg.agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_agents = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\pettingzoo\\utils\\conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 5, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = simple_adversary_v3.parallel_env(max_cycles=max_cycles)\n",
    "observations, infos = env.reset() if seed == -1 else env.reset(seed=seed)\n",
    "\n",
    "env_action_dims = []\n",
    "for action_space_key, action_space in env.action_spaces.items():\n",
    "    env_action_dims.append(action_space.n)\n",
    "\n",
    "env_action_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [23:51<39:21:20, 1431.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 0, 'agent_0': 3, 'agent_1': 0}\n",
      "Episode: 1, [1.3914398113762354, 1.3914398113762354, 1.3914398113762354, 1.3914398113762354, 1.3914398113762354, 1.3914398113762354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [47:40<38:56:05, 1430.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 3, 'agent_0': 0, 'agent_1': 1}\n",
      "Episode: 2, [-4.119090953003203, -4.119090953003203, -4.119090953003203, -4.119090953003203, -4.119090953003203, -4.119090953003203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [1:11:31<38:32:27, 1430.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 0, 'agent_0': 3, 'agent_1': 1}\n",
      "Episode: 3, [-11.387684806356647, -11.387684806356647, -11.387684806356647, -11.387684806356647, -11.387684806356647, -11.387684806356647]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [1:35:22<38:09:02, 1430.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 4, 'agent_0': 3, 'agent_1': 0}\n",
      "Episode: 4, [-12.042206386227685, -12.042206386227685, -12.042206386227685, -12.042206386227685, -12.042206386227685, -12.042206386227685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [1:59:11<37:44:27, 1430.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 4, 'agent_0': 3, 'agent_1': 1}\n",
      "Episode: 5, [-12.099550635891804, -12.099550635891804, -12.099550635891804, -12.099550635891804, -12.099550635891804, -12.099550635891804]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [2:23:02<37:20:46, 1430.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 4, 'agent_0': 3, 'agent_1': 4}\n",
      "Episode: 6, [-3.7928995959331706, -3.7928995959331706, -3.7928995959331706, -3.7928995959331706, -3.7928995959331706, -3.7928995959331706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [2:46:52<36:57:06, 1430.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 0, 'agent_0': 0, 'agent_1': 1}\n",
      "Episode: 7, [2.1920368017982623, 2.1920368017982623, 2.1920368017982623, 2.1920368017982623, 2.1920368017982623, 2.1920368017982623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [3:10:43<36:33:21, 1430.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 0, 'agent_0': 4, 'agent_1': 1}\n",
      "Episode: 8, [0.6045158152512168, 0.6045158152512168, 0.6045158152512168, 0.6045158152512168, 0.6045158152512168, 0.6045158152512168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [3:34:34<36:09:57, 1430.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 0, 'agent_0': 3, 'agent_1': 1}\n",
      "Episode: 9, [-1.4192568053099064, -1.4192568053099064, -1.4192568053099064, -1.4192568053099064, -1.4192568053099064, -1.4192568053099064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [3:58:26<35:46:28, 1430.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 4, 'agent_0': 0, 'agent_1': 4}\n",
      "Episode: 10, [-3.6663590955529592, -3.6663590955529592, -3.6663590955529592, -3.6663590955529592, -3.6663590955529592, -3.6663590955529592]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [4:22:18<35:22:59, 1431.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: {'adversary_0': 4, 'agent_0': 0, 'agent_1': 2}\n",
      "Episode: 11, [-8.109762073505614, -8.109762073505614, -8.109762073505614, -8.109762073505614, -8.109762073505614, -8.109762073505614]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [4:36:32<37:17:28, 1508.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 64\u001b[0m\n\u001b[0;32m     60\u001b[0m             en_maddpg\u001b[38;5;241m.\u001b[39mupdate(obs_tensor,act_tensor,rew_tensor,next_obs_tensor,done_tensor, a_i, desc, env_action_dims)\u001b[38;5;66;03m#(要素，agent编号) #感觉可以改成一次传参优化速度\u001b[39;00m\n\u001b[0;32m     61\u001b[0m         en_maddpg\u001b[38;5;241m.\u001b[39mupdate_all_targets()\n\u001b[1;32m---> 64\u001b[0m ep_returns \u001b[38;5;241m=\u001b[39m \u001b[43mrl_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43men_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_maddpg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_action_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43mused_agents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m return_list\u001b[38;5;241m.\u001b[39mappend(ep_returns)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, env_actions)\n",
      "File \u001b[1;32md:\\Disk_D\\CODE\\Python\\Graduation_Thesis\\DRPGA\\src\\utils\\rl_tools.py:84\u001b[0m, in \u001b[0;36men_evaluate\u001b[1;34m(env, maddpg, desc, env_action_dims, used_agents, n_episode, episode_length)\u001b[0m\n\u001b[0;32m     79\u001b[0m obs_padded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     80\u001b[0m agent_name: pad_to_shape(obs[agent_name], agent\u001b[38;5;241m.\u001b[39mobs_shape)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_name, agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(obs\u001b[38;5;241m.\u001b[39mkeys(), maddpg\u001b[38;5;241m.\u001b[39magents)\n\u001b[0;32m     82\u001b[0m }\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episode_length):\n\u001b[1;32m---> 84\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[43mmaddpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv_action_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43mused_agents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     e_acts \u001b[38;5;241m=\u001b[39m {agent: np\u001b[38;5;241m.\u001b[39margmax(action) \u001b[38;5;28;01mfor\u001b[39;00m agent, action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(env\u001b[38;5;241m.\u001b[39magents, actions)}\n\u001b[0;32m     87\u001b[0m     obs, rew, done,trun, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(e_acts)\n",
      "File \u001b[1;32md:\\Disk_D\\CODE\\Python\\Graduation_Thesis\\DRPGA\\models\\maddpg\\e2t_maddpg.py:155\u001b[0m, in \u001b[0;36mENMADDPG.take_action\u001b[1;34m(self, states, desc, env_action_dims, used_agents, explore)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcur_state:\u001b[39m\u001b[38;5;124m\"\u001b[39m,cur_states)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [agent\u001b[38;5;241m.\u001b[39mtake_action(state, desc, env_action_dims[i], explore) \u001b[38;5;28;01mfor\u001b[39;00m (i, agent), state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents), states)]\n",
      "File \u001b[1;32md:\\Disk_D\\CODE\\Python\\Graduation_Thesis\\DRPGA\\models\\maddpg\\e2t_maddpg.py:155\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcur_state:\u001b[39m\u001b[38;5;124m\"\u001b[39m,cur_states)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_action_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (i, agent), state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents), states)]\n",
      "File \u001b[1;32md:\\Disk_D\\CODE\\Python\\Graduation_Thesis\\DRPGA\\models\\maddpg\\e2t_maddpg.py:74\u001b[0m, in \u001b[0;36mENDDPG.take_action\u001b[1;34m(self, state, desc, env_action_dim, explore)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtake_action\u001b[39m(\u001b[38;5;28mself\u001b[39m,state,desc, env_action_dim, explore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m#print(\"state:\",state)\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombined_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m)[:env_action_dim]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m#print(\"action:\",action)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m explore:\n",
      "File \u001b[1;32md:\\Disk_D\\CODE\\Python\\Graduation_Thesis\\DRPGA\\models\\maddpg\\e2t_maddpg.py:63\u001b[0m, in \u001b[0;36mENDDPG.combined_input\u001b[1;34m(self, state, desc)\u001b[0m\n\u001b[0;32m     61\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m desc_token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     62\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m desc_token[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 63\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m     66\u001b[0m reduced_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_reduction(last_hidden_state)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    979\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    981\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    982\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    983\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    987\u001b[0m )\n\u001b[1;32m--> 988\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    572\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    573\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         output_attentions,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    511\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    512\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 514\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    526\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 527\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 439\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    441\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "return_list = [] \n",
    "total_step = 0\n",
    "replay_buffer = rl_tools.ReplayBuffer(buffer_size)\n",
    "\n",
    "agents = ['adversary_0', 'agent_0', 'agent_1']\n",
    "\n",
    "\n",
    "\n",
    "for i_episode in tqdm(range(num_episodes)):   \n",
    "   \n",
    "    state, info = env.reset() if seed == -1 else env.reset(seed=seed)\n",
    "    #print(state)\n",
    "    state_padded = {\n",
    "        agent_name: pad_to_shape(state[agent_name], agent.obs_shape)\n",
    "        for agent_name, agent in zip(state.keys(), en_maddpg.agents)\n",
    "    }\n",
    "    for e_i in range(episode_length):   \n",
    "        #print(type(desc))\n",
    "        actions = en_maddpg.take_action(state_padded, desc,env_action_dims, used_agents, explore=True)\n",
    "     \n",
    "        env_actions = {agent: np.argmax(action) for agent, action in zip(agents, actions)}\n",
    "\n",
    "        next_state, reward, done, truncations, infos = env.step(env_actions)\n",
    "        #print(next_state)\n",
    "        next_state_padded = {\n",
    "            agent_name: pad_to_shape(next_state[agent_name], agent.obs_shape)\n",
    "            for agent_name, agent in zip(next_state.keys(), en_maddpg.agents)\n",
    "        }\n",
    "        actions_padded = {\n",
    "            agent_name: pad_to_shape(actions[i], agent.action_shape)\n",
    "            for (i,agent_name), agent in zip(enumerate(agents), en_maddpg.agents)\n",
    "        }\n",
    "        #print(actions_padded)\n",
    "        replay_buffer.add(state_padded, actions_padded, reward, next_state_padded, done)\n",
    "        state_padded = next_state_padded\n",
    "\n",
    "        total_step += 1\n",
    "\n",
    "        if replay_buffer.size() >= minimal_size and total_step % update_interval == 0:\n",
    "            obs, act, rew, next_obs, done = replay_buffer.sample(batch_size)\n",
    "            #print(obs)\n",
    "            obs_list, act_list, rew_list, next_obs_list, done_list = [], [], [], [], []\n",
    "\n",
    "            for i, agent in enumerate(['adversary_0', 'agent_0', 'agent_1']):\n",
    "                obs_list.append(np.array([s[agent] for s in obs]))\n",
    "                #print(act)\n",
    "                act_list.append(np.array([a[agents[i]] for a in act]))\n",
    "                rew_list.append(np.array([r[agent] for r in rew]))\n",
    "                next_obs_list.append(np.array([ns[agent] for ns in next_obs]))\n",
    "                done_list.append(np.array([d[agent] for d in done]))\n",
    "\n",
    "            obs_tensor = [torch.tensor(o, dtype=torch.float32).to(device) for o in obs_list]\n",
    "            act_tensor = [torch.tensor(a, dtype=torch.float32).to(device) for a in act_list]\n",
    "            rew_tensor = [torch.tensor(r, dtype=torch.float32).to(device) for r in rew_list]                 \n",
    "            next_obs_tensor = [torch.tensor(n, dtype=torch.float32).to(device) for n in next_obs_list]\n",
    "            done_tensor = [torch.tensor(d, dtype=torch.float32).to(device) for d in done_list]  # 将布尔类型转换为浮点数类型\n",
    "\n",
    "\n",
    "            for a_i in range(len(env.agents)):\n",
    "                en_maddpg.update(obs_tensor,act_tensor,rew_tensor,next_obs_tensor,done_tensor, a_i, desc, env_action_dims)#(要素，agent编号) #感觉可以改成一次传参优化速度\n",
    "            en_maddpg.update_all_targets()\n",
    "\n",
    "\n",
    "    ep_returns = rl_tools.en_evaluate(env, en_maddpg,desc, env_action_dims,used_agents, n_episode=100)\n",
    "    return_list.append(ep_returns)\n",
    "   \n",
    "    print(\"actions:\", env_actions)\n",
    "    print(f\"Episode: {i_episode+1}, {ep_returns}\")\n",
    "  \n",
    "             \n",
    "env.close()\n",
    "\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "return_array = np.array(return_list)\n",
    "\n",
    "return_info = np.array([max_cycles,seed,num_episodes])\n",
    "\n",
    "np.savez(f'././evaluation/results/e2t_maddpg/{current_time}.npz',return_array=return_array, return_info=return_info) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(en_maddpg, './parameters/weights/en_maddpgs/en_maddpg_{curtime}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pettingZoo_Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
