{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import re\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
    "from datasets import Features, Value\n",
    "from datasets import  load_dataset, DownloadConfig\n",
    "from collections import deque,defaultdict\n",
    "import pickle\n",
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from src.utils.data_utils import format_data_sfsa\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pettingzoo.mpe import simple_adversary_v3\n",
    "from src.utils import rl_tools\n",
    "from models.maddpg.e2t_maddpg import ENMADDPG\n",
    "from models.utils import persistence\n",
    "from src.utils.data_utils import find_latest_file\n",
    "from src.utils.model_utils import pad_to_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "max_cycles = 200\n",
    "seed = 42\n",
    "\n",
    "num_episodes = 100\n",
    "episode_length = 2 \n",
    "buffer_size = 100000\n",
    "hidden_dim = 64\n",
    "actor_lr = 1e-2\n",
    "critic_lr = 1e-2\n",
    "gamma = 0.95\n",
    "tau = 1e-2\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "update_interval = 32\n",
    "minimal_size = 15\n",
    "replay_buffer = rl_tools.ReplayBuffer(buffer_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building EN_maddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_out_dim = 768\n",
    "redu_dim = 16\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_agents = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_en_dim(state_dim, redu_dim):\n",
    "\n",
    "    en_state_dims = []\n",
    "    for x in state_dim:\n",
    "        en_state_dims.append(x + redu_dim)\n",
    "    return en_state_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 50, 50, 50, 50]\n",
      "[50, 50, 50, 50, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "state_dims=[34, 34, 34, 34, 34, 34] \n",
    "action_dims=[50, 50, 50, 50, 50, 50] \n",
    "\n",
    "en_state_dims = add_en_dim(state_dims, redu_dim)\n",
    "\n",
    "\n",
    "print(en_state_dims)\n",
    "print(action_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_input_dim = sum(state_dims) +sum(action_dims) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "print(critic_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_dir = './parameters/weights/encoders/bert_EN'\n",
    "spec_en = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.load(spec_en) if spec_en else torch.load(find_latest_file(encoders_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = \"bert-base-uncased\"\n",
    "tokenizer_fn = \"tokenizer_fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n",
      "ENDDPG 768 16 34 50 504 64 0.01 0.01 cuda\n"
     ]
    }
   ],
   "source": [
    "en_maddpg = ENMADDPG(\n",
    "    tokenizer, \n",
    "    tokenizer_fn,\n",
    "    max_length,\n",
    "    encoder, \n",
    "    en_out_dim, \n",
    "    redu_dim, \n",
    "    max_agents, \n",
    "    device, \n",
    "    actor_lr, \n",
    "    critic_lr, \n",
    "    hidden_dim, \n",
    "    state_dims, \n",
    "    action_dims, \n",
    "    critic_input_dim, \n",
    "    gamma, \n",
    "    tau\n",
    "    )\n",
    "en_maddpg = en_maddpg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660155844 B parameters in en_maddpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sum(p.numel() for p in en_maddpg.parameters())/1e9,'B parameters in en_maddpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training EN_MADDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_mpe_env_raw = load_dataset(\"graycatHCO3/RL_MPE_env_raw\")\n",
    "rl_mpe_env_raw = load_from_disk('./data/HuggingFace/RL_MPE_env_raw');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_mpe_env_raw.save_to_disk('./data/HuggingFace/RL_MPE_env_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple.txt',\n",
       " 'simple_adversary.txt',\n",
       " 'simple_crypto.txt',\n",
       " 'simple_push.txt',\n",
       " 'simple_reference.txt',\n",
       " 'simple_speaker_listener.txt',\n",
       " 'simple_spread.txt',\n",
       " 'simple_tag.txt',\n",
       " 'simple_world_comm.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_mpe_env_raw['RL_MPE_raw']['Env_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = rl_mpe_env_raw['RL_MPE_raw']['content'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_maddpg.agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_agents = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\pettingzoo\\utils\\conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 5, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = simple_adversary_v3.parallel_env(max_cycles=max_cycles)\n",
    "observations, infos = env.reset() if seed == -1 else env.reset(seed=seed)\n",
    "\n",
    "env_action_dims = []\n",
    "for action_space_key, action_space in env.action_spaces.items():\n",
    "    env_action_dims.append(action_space.n)\n",
    "\n",
    "env_action_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_list = [] \n",
    "total_step = 0\n",
    "replay_buffer = rl_tools.ReplayBuffer(buffer_size)\n",
    "\n",
    "agents = ['adversary_0', 'agent_0', 'agent_1']\n",
    "\n",
    "\n",
    "\n",
    "for i_episode in tqdm(range(num_episodes)):   \n",
    "   \n",
    "    state, info = env.reset() if seed == -1 else env.reset(seed=seed)\n",
    "    #print(state)\n",
    "    state_padded = {\n",
    "        agent_name: pad_to_shape(state[agent_name], agent.obs_shape)\n",
    "        for agent_name, agent in zip(state.keys(), en_maddpg.agents)\n",
    "    }\n",
    "    for e_i in range(episode_length):   \n",
    "        #print(type(desc))\n",
    "        actions = en_maddpg.take_action(state_padded, desc,env_action_dims, used_agents, explore=True)\n",
    "     \n",
    "        env_actions = {agent: np.argmax(action) for agent, action in zip(agents, actions)}\n",
    "\n",
    "        next_state, reward, done, truncations, infos = env.step(env_actions)\n",
    "        #print(next_state)\n",
    "        next_state_padded = {\n",
    "            agent_name: pad_to_shape(next_state[agent_name], agent.obs_shape)\n",
    "            for agent_name, agent in zip(next_state.keys(), en_maddpg.agents)\n",
    "        }\n",
    "        actions_padded = {\n",
    "            agent_name: pad_to_shape(actions[i], agent.action_shape)\n",
    "            for (i,agent_name), agent in zip(enumerate(agents), en_maddpg.agents)\n",
    "        }\n",
    "        #print(actions_padded)\n",
    "        replay_buffer.add(state_padded, actions_padded, reward, next_state_padded, done)\n",
    "        state_padded = next_state_padded\n",
    "\n",
    "        total_step += 1\n",
    "\n",
    "        if replay_buffer.size() >= minimal_size and total_step % update_interval == 0:\n",
    "            obs, act, rew, next_obs, done = replay_buffer.sample(batch_size)\n",
    "            #print(obs)\n",
    "            obs_list, act_list, rew_list, next_obs_list, done_list = [], [], [], [], []\n",
    "\n",
    "            for i, agent in enumerate(['adversary_0', 'agent_0', 'agent_1']):\n",
    "                obs_list.append(np.array([s[agent] for s in obs]))\n",
    "                #print(act)\n",
    "                act_list.append(np.array([a[agents[i]] for a in act]))\n",
    "                rew_list.append(np.array([r[agent] for r in rew]))\n",
    "                next_obs_list.append(np.array([ns[agent] for ns in next_obs]))\n",
    "                done_list.append(np.array([d[agent] for d in done]))\n",
    "\n",
    "            obs_tensor = [torch.tensor(o, dtype=torch.float32).to(device) for o in obs_list]\n",
    "            act_tensor = [torch.tensor(a, dtype=torch.float32).to(device) for a in act_list]\n",
    "            rew_tensor = [torch.tensor(r, dtype=torch.float32).to(device) for r in rew_list]                 \n",
    "            next_obs_tensor = [torch.tensor(n, dtype=torch.float32).to(device) for n in next_obs_list]\n",
    "            done_tensor = [torch.tensor(d, dtype=torch.float32).to(device) for d in done_list]  # 将布尔类型转换为浮点数类型\n",
    "\n",
    "\n",
    "            for a_i in range(len(env.agents)):\n",
    "                en_maddpg.update(obs_tensor,act_tensor,rew_tensor,next_obs_tensor,done_tensor, a_i, desc, env_action_dims)#(要素，agent编号) #感觉可以改成一次传参优化速度\n",
    "            en_maddpg.update_all_targets()\n",
    "\n",
    "\n",
    "    ep_returns = rl_tools.en_evaluate(env, en_maddpg,desc, env_action_dims,used_agents, n_episode=100)\n",
    "    return_list.append(ep_returns)\n",
    "   \n",
    "    print(\"actions:\", env_actions)\n",
    "    print(f\"Episode: {i_episode+1}, {ep_returns}\")\n",
    "  \n",
    "             \n",
    "env.close()\n",
    "\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "return_array = np.array(return_list)\n",
    "\n",
    "return_info = np.array([max_cycles,seed,num_episodes])\n",
    "\n",
    "np.savez(f'././evaluation/results/e2t_maddpg/{current_time}.npz',return_array=return_array, return_info=return_info) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(en_maddpg, './parameters/weights/en_maddpgs/en_maddpg_{curtime}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training MADDPG_DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"graycatHCO3/Simple_SFSA_e2t_0200\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['turn', 'details', 'dialogue', 'dataset_name'],\n",
       "        num_rows: 12105\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b76099450348f1afb7369a23bf5778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理后的数据集结构: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['turn', 'details', 'dialogue', 'dataset_name', 'inputs', 'targets'],\n",
      "        num_rows: 12105\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_input(batch):\n",
    "    formatted_inputs = []\n",
    "    for example in zip(batch['turn'], batch['details'], batch['dataset_name']):\n",
    "        turn_info = f\"Turn: {example[0]}\"\n",
    "        details = f\"Details: {example[1]}\"\n",
    "        dataset_name = f\"Dataset Name: {example[2]}\"\n",
    "        formatted_inputs.append(f\"{turn_info}. {details}. {dataset_name}.\")\n",
    "    return formatted_inputs\n",
    "\n",
    "\n",
    "def preprocess_data(batch):\n",
    "    inputs = format_input(batch)\n",
    "    targets = batch['dialogue']\n",
    "    return {\"inputs\": inputs, \"targets\": targets}\n",
    "\n",
    "dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "print(\"预处理后的数据集结构:\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_DE = torch.load('./parameters/weights/transformers/bert_ED/bert_ED_full.pth').get_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, EncoderDecoderModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenizer_fn(examples):\n",
    "    inputs = bert_tokenizer(examples[\"inputs\"], max_length=128, padding=\"max_length\", truncation=True)\n",
    "    with bert_tokenizer.as_target_tokenizer():\n",
    "        labels = bert_tokenizer(examples[\"targets\"], max_length=128, padding=\"max_length\", truncation=True)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "bert_tkd = dataset.map(tokenizer_fn, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为 PyTorch Tensor\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.tensor([item['input_ids'] for item in batch])\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(bert_tkd, batch_size=16, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(bert_ED.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "        outputs = bert_DE(input_ids=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pettingZoo_Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
