{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example: TRTF_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0.024341504 B parameters in tr_tf_en\n",
      "TRTF_en output shape torch.Size([10, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "from models.transformers import torch_Transformer\n",
    "from src.utils import model_utils\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = 10000\n",
    "d_model = 512  \n",
    "n_head = 8\n",
    "en_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 600\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "tr_tf_en = torch_Transformer.TRTF_encoder(vocab_size, d_model, \n",
    "    n_head, en_layers, d_ff, max_seq_length)\n",
    "\n",
    "tr_tf_en = tr_tf_en.to(device)\n",
    "tr_tf_en = tr_tf_en.bfloat16()\n",
    "\n",
    "\n",
    "\n",
    "print(sum(p.numel() for p in tr_tf_en.parameters())/1e9, 'B parameters in tr_tf_en')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "src = torch.randint(0, vocab_size, (10, 32))\n",
    "src_mask = model_utils.square_subsequent_mask(10)\n",
    "\n",
    "\n",
    "src = src.to(device)\n",
    "\n",
    "src_mask = src_mask.to(device)\n",
    "src_mask = src_mask.bfloat16()\n",
    "\n",
    "\n",
    "output = tr_tf_en.forward(src,src_mask)\n",
    "print(\"TRTF_en output shape\",output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTF_TRTF_encoder Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. h4ca20k_py pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4ca20k_py = load_dataset(\"graycatHCO3/CodeAlpaca-20K-Python\")\n",
    "#h4ca20k_py = load_dataset(\"./data/codeNLU/h4ca20k_py/h4ca20k_py_.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 4777\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 548\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(h4ca20k_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformers import torch_Transformer\n",
    "from src.utils import model_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#vocab_size = 1000\n",
    "d_model = 512  \n",
    "n_head = 8\n",
    "en_layers = 6\n",
    "d_ff = 512\n",
    "max_seq_length = 512\n",
    "out_dim = 64\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) By BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # 确保输出为Tensor\n",
    "    input_ids = tokenizer(examples['completion'], truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\").input_ids\n",
    "    labels = tokenizer(examples['prompt'], truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\").input_ids\n",
    "    return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "\n",
    "\n",
    "tokenized_datasets = h4ca20k_py.map(tokenize_function, batched=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'labels'],\n",
      "        num_rows: 4777\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion', 'input_ids', 'labels'],\n",
      "        num_rows: 548\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041015098 B parameters in ptf_trtf_en\n"
     ]
    }
   ],
   "source": [
    "ptf_trtf_en = torch_Transformer.paddingT_FTRTF_encoder(vocab_size, d_model, \n",
    "    n_head, en_layers, d_ff, out_dim, max_seq_length)\n",
    "\n",
    "ptf_trtf_en = ptf_trtf_en.to(device)\n",
    "#ptf_trtf_en = ptf_trtf_en.bfloat16()\n",
    "#ptf_trtf_en.eval()\n",
    "optimizer = AdamW(ptf_trtf_en.parameters(), lr = 5e-5)\n",
    "\n",
    "print(sum(p.numel() for p in ptf_trtf_en.parameters())/1e9, 'B parameters in ptf_trtf_en')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # 使用torch.stack来组合Tensor，确保所有item已正确转换为Tensor\n",
    "    input_ids = torch.stack([torch.tensor(item['input_ids']) for item in batch])\n",
    "    labels = torch.stack([torch.tensor(item['labels']) for item in batch])\n",
    "    return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(tokenized_datasets['test'], batch_size=8, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        if isinstance(batch['input_ids'], list):\n",
    "            batch['input_ids'] = torch.tensor(batch['input_ids'])\n",
    "            batch['labels'] = torch.tensor(batch['labels'])\n",
    "        inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print(inputs.size())\n",
    "        #print(f\"src shape before processing: {inputs.squeeze(1).shape}\")  # 打印src的形状\n",
    "        outputs = model(inputs.squeeze(1))\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(outputs.shape[1]):\n",
    "            loss += F.cross_entropy(outputs[:, i, :], labels[:, i])\n",
    "        loss /= outputs.shape[1]  # 平均损失\n",
    "\n",
    "        #loss = criterion(outputs, labels.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs =10\n",
    "best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape before processing: torch.Size([8, 512])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 478.00 MiB (GPU 0; 4.00 GiB total capacity; 3.27 GiB already allocated; 0 bytes free; 3.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 2\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptf_trtf_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(ptf_trtf_en, val_dataloader, criterion, device)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[107], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(inputs.size())\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc shape before processing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 打印src的形状\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\CODE\\Python\\Graduation_Thesis\\DRPGA\\models\\transformers\\torch_Transformer.py:73\u001b[0m, in \u001b[0;36mpaddingT_FTRTF_encoder.forward\u001b[1;34m(self, src, src_mask)\u001b[0m\n\u001b[0;32m     71\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[39m#output = self.pooling(output).squeeze(-1)\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_layer(output)\n\u001b[0;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Disk_D\\programming_software\\AI\\Anaconda3\\envs\\pettingZoo_Langchain\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 478.00 MiB (GPU 0; 4.00 GiB total capacity; 3.27 GiB already allocated; 0 bytes free; 3.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(ptf_trtf_en, train_dataloader, optimizer, criterion, device)\n",
    "    val_loss = validate(ptf_trtf_en, val_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(ptf_trtf_en.state_dict(),'ptf_trtf_en.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RL_env pretrianing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import BertTokenizer\n",
    "from src.utils import data_utils\n",
    "\n",
    "with open('./data/RL_env/Pettingzoo_mpe/simple_adversary.json','r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "formed_data = data_utils.json2Tpath(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_codes = dataset.filter(lambda example: example['langu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = []\n",
    "for path, text in formed_data:\n",
    "    tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "    tokenized_data.append((path,tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002778176 B parameters in tr_tf_en\n"
     ]
    }
   ],
   "source": [
    "from models.transformers import torch_Transformer\n",
    "from src.utils import model_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = 1000\n",
    "d_model = 256  \n",
    "n_head = 8\n",
    "en_layers = 6\n",
    "d_ff = 256\n",
    "max_seq_length = 512\n",
    "out_dim = 64\n",
    "\n",
    "\n",
    "\n",
    "ptf_trtf_en = torch_Transformer.paddingT_FTRTF_encoder(vocab_size, d_model, \n",
    "    n_head, en_layers, d_ff, out_dim, max_seq_length)\n",
    "\n",
    "ptf_trtf_en = ptf_trtf_en.to(device)\n",
    "ptf_trtf_en = ptf_trtf_en.bfloat16()\n",
    "ptf_trtf_en.eval()\n",
    "\n",
    "\n",
    "print(sum(p.numel() for p in ptf_trtf_en.parameters())/1e9, 'B parameters in tr_tf_en')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path, tokens \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenized_data\u001b[49m:\n\u001b[0;32m      5\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_data' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_data = []\n",
    "\n",
    "\n",
    "for path, tokens in tokenized_data:\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask'].to(dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        output = ptf_trtf_en(input_ids, attention_mask)\n",
    "    encoded_data.append((path, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('pettingZoo_Langchain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afdf63005a8e15303df45d0cecdfecb72eda57fa0cd442cd104881763b83185d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
